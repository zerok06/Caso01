from core.chat_service import send_ai_message_to_chat
from models.document import Document

# Palabras clave para interpretar confirmaci칩n del usuario
AFFIRM = ["si", "s칤", "ver", "ver m치s", "mostrar", "mu칠strame", "ok", "dale", "quiero", "detallado"]


def process_incoming_user_message(db, workspace_id: str, conversation_id: str, content: str):
    """
    Router inteligente:
    - Si el usuario confirma -> env칤a ANALISIS COMPLETO del documento m치s reciente.
    - Si NO confirma -> no hace nada (chat normal).
    """

    normalized = content.lower().strip()

    # 쮼l usuario no est치 pidiendo ver el an치lisis completo?
    if not any(k in normalized for k in AFFIRM):
        return None

    # Buscar el documento m치s reciente con sugerencias generadas
    doc = (
        db.query(Document)
        .filter(Document.workspace_id == workspace_id)
        .order_by(Document.created_at.desc())
        .first()
    )

    if not doc or not doc.suggestion_full:
        return send_ai_message_to_chat(
            db,
            workspace_id,
            conversation_id,
            "No encontr칠 un an치lisis reciente para mostrar."
        )

    # Enviar el an치lisis completo al chat
    return send_ai_message_to_chat(
        db,
        workspace_id,
        conversation_id,
        f"游늯 **An치lisis completo del documento:**\n\n{doc.suggestion_full}"
    )


# ------------------------------------------------------------
# 游녤 Funci칩n p칰blica que usar치 tu endpoint
# ------------------------------------------------------------

def handle_user_message(db, workspace_id: str, conversation_id: str, content: str):
    """
    Punto de entrada oficial para el endpoint de chat.
    Simplemente llama al router inteligente.
    """
    return process_incoming_user_message(
        db=db,
        workspace_id=workspace_id,
        conversation_id=conversation_id,
        content=content
    )
